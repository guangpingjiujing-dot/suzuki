# データエンジニア・アナリティクスエンジニア向け Python カリキュラム

## 学習目標
データエンジニア・アナリティクスエンジニアとして実務で必要な Python スキルを段階的に習得する

---

## カリキュラム概要

### 1. Python 基礎
- 基本的な構文とデータ型（文字列、数値、リスト、辞書、タプル）
- 制御構造（if文、for文、while文）
- 関数の定義と使い方
- モジュールとパッケージの概念
- エラーハンドリング（try-except）

### 2. データ処理ライブラリ
- **pandas**
  - DataFrame の基本操作（作成、読み込み、書き込み）
  - データの選択、フィルタリング、ソート
  - データの結合（merge、concat）
  - グループ化と集計（groupby）
  - 欠損値の処理
  - データ型の変換
- **numpy**
  - 配列の基本操作
  - 基本的な数値計算

### 3. データの読み込み・書き込み
- CSV、Excel ファイルの読み込み・書き込み
- JSON データの処理
- API からのデータ取得

### 4. BigQuery 連携
- **google-cloud-bigquery** ライブラリの使い方
- BigQuery への接続と認証設定
- BigQuery からのデータ読み込み（クエリ実行、テーブル読み込み）
- BigQuery へのデータ書き込み（テーブル作成、データロード）
- pandas と BigQuery の連携（to_gbq、read_gbq）
- BigQuery クエリの Python からの実行
- パーティション、クラスタリングを考慮したデータロード
- クエリ結果の効率的な処理

### 5. データ可視化
- **matplotlib** の基本
- **seaborn** を使った統計的可視化
- 実務でよく使うグラフの作成（折れ線、棒、散布図、ヒートマップ等）

### 6. データ変換・ETL 処理
- データのクリーニングと前処理
- データの変換と整形
- 複数データソースの統合
- BigQuery を中心とした ETL パイプラインの実装
- pandas を使ったデータ変換と BigQuery へのロード
- 増分ロード（Incremental Load）の実装

### 7. データ分析の実践
- 基本的な統計処理
- 時系列データの処理
- データの集計と集約
- 実務でよく使う分析パターンの実装

### 8. データ品質・検証
- データの妥当性チェック
- データの整合性確認
- 異常値の検出

### 9. PySpark による大規模データ処理
- **PySpark** の基本概念と Spark のアーキテクチャ
- SparkSession の作成と設定
- DataFrame API の基本操作
- Spark SQL の使い方
- データの読み込み・書き込み（CSV、Parquet、JSON 等）
- データ変換と集計処理
- パフォーマンス最適化（パーティション、キャッシュ、ブロードキャスト）
- BigQuery と PySpark の連携（BigQuery Storage API の活用）
- 分散処理の概念とベストプラクティス

### 10. Apache Iceberg によるデータレイク管理
- **Apache Iceberg** の基本概念と特徴
- Iceberg テーブルの作成と管理
- スキーマの進化（Schema Evolution）
- タイムトラベルとバージョン管理
- パーティション戦略の設計
- PySpark と Iceberg の連携
- BigQuery と Iceberg の連携（外部テーブルとしての利用）
- データレイクハウスアーキテクチャの理解

### 11. 開発環境とツール
- **uv** ─ パッケージ・プロジェクトマネージャ
  - プロジェクトの初期化（uv init）
  - パッケージの追加・削除（uv add、uv remove）
  - Python バージョンの管理（uv python）
  - スクリプトの実行（uv run）
  - 依存関係の管理（uv.lock、uv sync）
  - 仮想環境の自動管理
- **Ruff** ─ 高速なリンタ・フォーマッタ
  - コードの品質チェック（ruff check）
  - コードの自動整形（ruff format）
  - コーディング規約（PEP 8）の自動チェック
- **mypy** ─ 静的型検査
  - 型ヒントの記述方法
  - 型検査の実行とエラー検出
  - 型推論の理解
- **poethepoet** ─ タスクランナー
  - よく使うコマンドの定義と実行
  - pyproject.toml での設定管理
- **pre-commit** ─ コミット前チェック
  - Git フックの設定
  - コミット前の自動チェック（フォーマット、リント、型検査）
- **Jupyter Notebook** の使い方
  - データ分析での活用方法
  - BigQuery との連携

### 12. パフォーマンスと最適化
- 大きなデータセットの効率的な処理
- メモリ使用量の最適化
- 基本的な並列処理の概念

### 13. テストとデバッグ
- ユニットテストの基本
- デバッグ手法
- ログの活用

---

## 学習の進め方（案）
1. 基礎から順番に学習を進める
2. 各トピックで実際のデータを使った演習を行う
3. 実務でよくあるシナリオを想定した課題に取り組む
4. 段階的に難易度を上げていく
